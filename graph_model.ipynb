{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "import re\n",
    "import jieba.posseg as pseg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration of LDA and NMF for text analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weicheng(filename='story.txt'):\n",
    "    lines = open(filename).readlines()\n",
    "    books = []\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        if line.startswith('第') and line.endswith('章'):\n",
    "            books.append(line)\n",
    "        else:\n",
    "            books[-1] += line\n",
    "    for i in range(len(books)):\n",
    "        books[i] = ' '.join(jieba.cut(books[i]))\n",
    "    return books\n",
    "\n",
    "def load_honglou(filename='honglou.txt'):\n",
    "    lines = open(filename).readlines()\n",
    "    book = [[]]\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        if '书香屋' in line:\n",
    "            book[-1].pop()\n",
    "            book.append([])\n",
    "        else:\n",
    "            book[-1].append(line)\n",
    "    return [' '.join(jieba.cut(''.join(chp))) for chp in book]\n",
    "\n",
    "def load_xiyou(filename='xiyouji_wuchengen.txt'):\n",
    "    \n",
    "    def _is_sep(line):\n",
    "        pat = re.compile(u'第.{1,3}回')\n",
    "        if pat.search(line):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    lines = open(filename).readlines()\n",
    "    book = [[]]\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        if _is_sep(line):\n",
    "            book.append([])\n",
    "        else:\n",
    "            book[-1].append(line)\n",
    "    print(len(book))\n",
    "    book = [''.join(chp) for chp in book if len(chp)]\n",
    "    book_noun = []\n",
    "    for chp in book:\n",
    "        words = pseg.cut(chp)\n",
    "        #book_noun.append( ' '.join([word for word, flag in words if flag[0] == 'n']))\n",
    "        book_noun.append( ' '.join(jieba.cut(chp)))\n",
    "    return book_noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/sulixin/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:314: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:行者 八戒 师父 妖精 一个 沙僧 唐僧 我们 怎么 那里 大圣 三藏 和尚 那怪 呆子 不知 甚么 两个 小妖 大王\n",
      "Topic 1:意思 故事 后来 佛教 形容 称为 古代 一种 这里 比喻 这是 又称 所以 梵语 因为 道教 典故 人们 唐代 之一\n",
      "Topic 2:国王 公主 驸马 陛下 八戒 关文 寡人 驿丞 长老 倒换 行者 国师 神僧 多官 娘娘 贫僧 文武 和尚 万岁 唐僧\n",
      "Topic 3:三藏 长老 老者 师父 贫僧 圣僧 徒弟 十八 驿丞 和尚 袈裟 员外 老爷 女子 老母 不敢 大唐 师徒 我们 取经\n",
      "Topic 4:大圣 天王 玉帝 李天王 太子 哪吒 真君 金星 妖猴 如来 猴王 蟠桃 齐天大圣 仙女 老君 二郎 四大 下界 天宫 圈子\n",
      "Topic 5:祖师 悟空 猴王 美猴王 大王 龙王 花果山 神仙 水帘洞 乃是 大众 弟子 魔王 一个 甚么 金星 孙悟空 天地 兵器 观看\n",
      "Topic 6:菩萨 如来 木叉 袈裟 取经 南海 莲台 观音 一个 弟子 大仙 锡杖 怪物 大众 王道 金刚 诸天 南无 宝杖 花果山\n",
      "Topic 7:太宗 唐王 陛下 魏征 南无 判官 玄奘 金银 袈裟 阎王 法师 谢恩 御弟 文武 天下 锡杖 多官 光蕊 夫妻 传旨\n",
      "Topic 8:道教 传说 先生 天尊 天师 道士 神仙 又称 婆婆 真人 这里 地方 八卦 认为 说法 古时 元帅 之一 天神 西游记\n",
      "Topic 9:罗刹 扇子 牛王 大圣 芭蕉扇 土地 女子 芭蕉 牛魔王 猢狲 老者 魔王 公主 宝贝 变作 夫人 王道 宝剑 一只 金刚\n",
      "\n",
      "LDA\n",
      "Topic 0:三藏 师父 行者 形容 大圣 这里 一个 八戒 意思 后来 不知 唐僧 那里 不是 所以 古代 小龙 土地 故事 甚么\n",
      "Topic 1:行者 八戒 师父 三藏 一个 大圣 沙僧 妖精 那里 怎么 唐僧 我们 不知 不是 菩萨 和尚 呆子 两个 只见 三个\n",
      "Topic 2:意思 这里 佛教 道教 形容 后来 古代 一种 传说 称为 故事 比喻 神仙 所以 一个 这是 就是 地方 又称 认为\n",
      "Topic 3:行者 八戒 师父 三藏 一个 唐僧 沙僧 怎么 那里 我们 大圣 和尚 妖精 不知 两个 菩萨 甚么 长老 不是 国王\n",
      "Topic 4:菩萨 太宗 御弟 南无 女王 袈裟 玄奘 三藏 长老 唐王 太师 圣僧 法师 行者 真经 锡杖 唐僧 取经 师父 徒弟\n",
      "Topic 5:大圣 菩萨 行者 天王 悟空 玉帝 一个 猴王 如来 不知 太宗 只见 那里 如何 两个 太子 大王 陛下 哪吒 龙王\n",
      "Topic 6:行者 菩萨 一个 这里 八戒 甚么 师父 唐僧 称为 就是 不知 袈裟 乃是 后来 猴王 两个 原来 那个 一种 今日\n",
      "Topic 7:八戒 国王 公主 三藏 师父 长老 唐僧 行者 菩萨 沙僧 两个 徒弟 和尚 陛下 如何 意思 不敢 不知 驸马 一个\n",
      "Topic 8:光蕊 玄奘 丞相 婆婆 母亲 龙王 我儿 和尚 打死 一个 师父 今日 夫人 只见 父母 长老 唐王 孩儿 夜叉 报仇\n",
      "Topic 9:八戒 行者 菩萨 师父 一个 佛教 大圣 意思 这里 三藏 后来 悟空 怎么 取经 甚么 不知 不是 故事 形容 沙僧\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "\n",
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print (\"Topic %d:\" % (topic_idx) + \" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]) )\n",
    "\n",
    "\n",
    "documents = load_xiyou()\n",
    "print()\n",
    "no_features = 1000\n",
    "\n",
    "# NMF is able to use tf-idf\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, max_features=no_features, stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(documents)\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "# LDA can only use raw term counts for LDA because it is a probabilistic graphical model\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=no_features, stop_words='english')\n",
    "tf = tf_vectorizer.fit_transform(documents)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "\n",
    "no_topics = 10\n",
    "\n",
    "# Run NMF\n",
    "nmf = NMF(n_components=no_topics, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd').fit(tfidf)\n",
    "\n",
    "# Run LDA\n",
    "lda = LatentDirichletAllocation(n_topics=no_topics, max_iter=20, learning_method='online', learning_offset=50.,random_state=0).fit(tf)\n",
    "\n",
    "no_top_words = 20\n",
    "display_topics(nmf, tfidf_feature_names, no_top_words)\n",
    "print('\\nLDA')\n",
    "display_topics(lda, tf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
